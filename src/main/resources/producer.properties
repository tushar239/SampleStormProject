# http://kafka.apache.org/documentation/#producerconfigs

# Bootstrap.servers, key.serializer, value.serializer are mandatory properties.

# An id string to pass to the server when making requests. The purpose of this is to be able to track the source of requests beyond just ip/port by allowing a logical application name to be included in server-side request logging.
client.id=testproducer

# brokers list
# If you are working on multi-node env, then it's better to provide more than one brokers addresses because if one goes down, producer can connect to another one.
bootstrap.servers=localhost:9092

# producer sends a string message to kafka and tells kafka to use StringSerializer to convert that string to bytes
# you can write your own custom serializer also

key.serializer=org.apache.kafka.common.serialization.StringSerializer
value.serializer=org.apache.kafka.common.serialization.StringSerializer

# The acks config controls the criteria under producer requests are considered complete.
# acks=0 If set to zero then the producer will not wait for any acknowledgment from the server at all. The record will be immediately added to the socket buffer and considered sent. No guarantee can be made that the server has received the record in this case, and the retries configuration will not take effect (as the client won't generally know of any failures). The offset given back for each record will always be set to -1.
# acks=1 This will mean the leader will write the record to its local log but will respond without awaiting full acknowledgement from all followers. In this case should the leader fail immediately after acknowledging the record but before the followers have replicated it then the record will be lost.
# acks=all This means the leader will wait for the full set of in-sync replicas to acknowledge the record. This guarantees that the record will not be lost as long as at least one in-sync replica remains alive. This is the strongest available guarantee. This is equivalent to the acks=-1 setting.

acks=all

# If producer request fails, then automatically retry with specific value.
# There are two types of errors can occur when producer tries to send a message to a topic
# 1. Retriable - e.g. leader was down. So, it takes some time to choose another leader by zookeeper. In this case retry makes sense
# 2. Non-Retriable

retries=0

# It's a Buffer size. Before producer sends records to broker, it creates a batch of records in its own buffer. You can configure the size of this buffer in properties.
# The producer will attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition. This helps performance on both the client and the server. This configuration controls the default batch size in bytes.
# No attempt will be made to batch records larger than this size.
# Requests sent to brokers will contain multiple batches, one for each partition with data available to be sent.

# batch.size=16384 # it is the default value

# Controls the total amount of memory available to the producer for buffering.
# The total bytes of memory the producer can use to buffer records waiting to be sent to the server. If records are sent faster than they can be delivered to the server the producer will block for max.block.ms after which it will throw an exception.
# This setting should correspond roughly to the total memory the producer will use, but is not a hard bound since not all memory the producer uses is used for buffering. Some additional memory will be used for compression (if compression is enabled) as well as for maintaining in-flight requests.

# buffer.memory=33554432 # it is the default value

auto.commit.interval.ms=1000

# if you want to reduce the number of requests you can set linger.ms to something greater than some value.
# By default a buffer is available to send immediately even if there is additional unused space in the buffer. However if you want to reduce the number of requests you can set linger.ms to something greater than 0. This will instruct the producer to wait up to that number of milliseconds before sending a request in hope that more records will arrive to fill up the same batch.

linger.ms=0

# The buffer.memory controls the total amount of memory available to the producer for buffering. If records are sent faster than they can be transmitted to the server then this buffer space will be exhausted. When the buffer space is exhausted additional send calls will block. For uses where you want to avoid any blocking you can set block.on.buffer.full=false which will cause the send call to result in an exception.
# This parameter is deprecated and will be removed in a future release. Parameter max.block.ms should be used instead.

block.on.buffer.full=true

# either sync or async
# I do not see the code sending the messages synchronously. producer.send(...) method always returns a Future. It means it sends batched records in background.
# producer.type=async # this is the default value